{
    "batch_size": 2048,
    "epochs": 200,
    "model": "mlp",
    "gpu": 1,
    "loss_alpha": 0.05
}